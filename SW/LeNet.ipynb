{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [default]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"LeNet","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Tiyi-oK8q1qe"},"source":["# LeNet Lab Solution\n","![LeNet Architecture](lenet.png)\n","Source: Yan LeCun"]},{"cell_type":"markdown","metadata":{"id":"0iQqvX3-q1qk"},"source":["## Load Data\n","\n","Load the MNIST data, which comes pre-loaded with TensorFlow.\n","\n","You do not need to modify this section."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmy5L3s8XeGv","executionInfo":{"status":"ok","timestamp":1630676964301,"user_tz":-540,"elapsed":42698,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"3dc69d57-238a-4835-87ee-65fedd037df9"},"source":["!pip uninstall tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: tensorflow 2.6.0\n","Uninstalling tensorflow-2.6.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.7/dist-packages/tensorflow-2.6.0.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n","Proceed (y/n)? ㅛ\n","Your response ('ㅛ') was not one of the expected responses: y, n\n","Proceed (y/n)? ㅛ\n","Your response ('ㅛ') was not one of the expected responses: y, n\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5KJu-ts82iy","executionInfo":{"status":"ok","timestamp":1630677512086,"user_tz":-540,"elapsed":40091,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"8d8205fb-88a8-498b-aa72-0a363b625e1c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"upU9rnhUXtfa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677019295,"user_tz":-540,"elapsed":55000,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"05707cb9-6c2d-4d2f-e69a-8f0b3a1fe520"},"source":["!pip install tensorflow==1.15 # 1.15 버전 Tensorflow 설치"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==1.15\n","  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n","\u001b[K     |████████████████████████████████| 412.3 MB 12 kB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 38.1 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n","Collecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[K     |████████████████████████████████| 503 kB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.39.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n","Collecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n","Collecting keras-applications>=1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.6.4)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.5.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=aae86d9c97e44ede1576f7fe0d5d629056816ca4c72afc02fee32f19b30a255e\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","Successfully built gast\n","Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.6.0\n","    Uninstalling tensorflow-estimator-2.6.0:\n","      Successfully uninstalled tensorflow-estimator-2.6.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.6.0\n","    Uninstalling tensorboard-2.6.0:\n","      Successfully uninstalled tensorboard-2.6.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"]}]},{"cell_type":"code","metadata":{"id":"Ut2Qe8Tvq1qm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677024932,"user_tz":-540,"elapsed":5645,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"ee8c9aa1-d289-47fc-c297-23c0b9fe8195"},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","import numpy as np\n","\n","mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n","X_train, y_train           = mnist.train.images, mnist.train.labels\n","X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n","X_test, y_test             = mnist.test.images, mnist.test.labels\n","\n","assert(len(X_train) == len(y_train))\n","assert(len(X_validation) == len(y_validation))\n","assert(len(X_test) == len(y_test))\n","\n","print()\n","print(\"Image Shape: {}\".format(X_train[0].shape))\n","print()\n","print(\"Training Set:   {} samples\".format(len(X_train)))\n","print(\"Validation Set: {} samples\".format(len(X_validation)))\n","print(\"Test Set:       {} samples\".format(len(X_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From <ipython-input-3-4b28aec08346>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","\n","Image Shape: (28, 28, 1)\n","\n","Training Set:   55000 samples\n","Validation Set: 5000 samples\n","Test Set:       10000 samples\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"SQ67EjHEq1qp"},"source":["from sklearn.utils import shuffle\n","\n","X_train, y_train = shuffle(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"FFTRMDARq1qq"},"source":["import tensorflow as tf\n","\n","EPOCHS = 100\n","BATCH_SIZE = 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkcSDy-qq1qq"},"source":["## SOLUTION: Implement LeNet-5\n","Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n","\n","This is the only cell you need to edit.\n","### Input\n","The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n","\n","### Architecture\n","**Layer 1: Convolutional.** The output shape should be 28x28x6.\n","\n","**Activation.** Your choice of activation function.\n","\n","**Pooling.** The output shape should be 14x14x6.\n","\n","**Layer 2: Convolutional.** The output shape should be 10x10x16.\n","\n","**Activation.** Your choice of activation function.\n","\n","**Pooling.** The output shape should be 5x5x16.\n","\n","**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n","\n","**Layer 3: Fully Connected.** This should have 120 outputs.\n","\n","**Activation.** Your choice of activation function.\n","\n","**Layer 4: Fully Connected.** This should have 84 outputs.\n","\n","**Activation.** Your choice of activation function.\n","\n","**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n","\n","### Output\n","Return the result of the 2nd fully connected layer."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"4btmqaz5q1qr"},"source":["from tensorflow.contrib.layers import flatten\n","\n","def LeNet(x):    \n","    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n","    mu = 0\n","    sigma = 0.1\n","    \n","    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n","    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n","    conv1_b = tf.Variable(tf.zeros(6))\n","    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n","\n","    # SOLUTION: Activation.\n","    conv1 = tf.nn.relu(conv1)\n","\n","    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n","    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n","\n","    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n","    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n","    conv2_b = tf.Variable(tf.zeros(16))\n","    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n","    \n","    # SOLUTION: Activation.\n","    conv2 = tf.nn.relu(conv2)\n","\n","    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n","    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n","\n","    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n","    fc0   = flatten(conv2)\n","    \n","    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n","    fc1_W = tf.Variable(tf.truncated_normal(shape=(256, 32), mean = mu, stddev = sigma))\n","    fc1_b = tf.Variable(tf.zeros(32))\n","    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n","    \n","    # SOLUTION: Activation.\n","    fc1    = tf.nn.relu(fc1)\n","\n","    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n","    fc2_W  = tf.Variable(tf.truncated_normal(shape=(32, 16), mean = mu, stddev = sigma))\n","    fc2_b  = tf.Variable(tf.zeros(16))\n","    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n","    \n","    # SOLUTION: Activation.\n","    fc2    = tf.nn.relu(fc2)\n","\n","    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n","    fc3_W  = tf.Variable(tf.truncated_normal(shape=(16, 10), mean = mu, stddev = sigma))\n","    fc3_b  = tf.Variable(tf.zeros(10))\n","    logits = tf.matmul(fc2, fc3_W) + fc3_b\n","    \n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyqGsGseq1qs"},"source":["x = tf.placeholder(tf.float32, (None, 28, 28, 1))\n","y = tf.placeholder(tf.int32, (None))\n","one_hot_y = tf.one_hot(y, 10)\n","rate = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR_2Tsz2q1qt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677025434,"user_tz":-540,"elapsed":518,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"280907f8-b455-4cb8-e349-172cb86303fe"},"source":["\n","\n","#logits=LeNet(x)\n","\n","\n","# Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n","mu = 0\n","sigma = 0.1\n","\n","# SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n","conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n","conv1_b = tf.Variable(tf.zeros(6))\n","conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n","\n","# SOLUTION: Activation.\n","conv1 = tf.nn.relu(conv1)\n","\n","# SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n","conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n","\n","# SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n","conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n","conv2_b = tf.Variable(tf.zeros(16))\n","conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n","\n","# SOLUTION: Activation.\n","conv2 = tf.nn.relu(conv2)\n","\n","# SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n","conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n","\n","# SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n","fc0   = flatten(conv2)\n","\n","# SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n","fc1_W = tf.Variable(tf.truncated_normal(shape=(256, 32), mean = mu, stddev = sigma))\n","fc1_b = tf.Variable(tf.zeros(32))\n","fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n","\n","# SOLUTION: Activation.\n","fc1    = tf.nn.relu(fc1)\n","\n","# SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n","fc2_W  = tf.Variable(tf.truncated_normal(shape=(32, 16), mean = mu, stddev = sigma))\n","fc2_b  = tf.Variable(tf.zeros(16))\n","fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n","\n","# SOLUTION: Activation.\n","fc2    = tf.nn.relu(fc2)\n","\n","# SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n","fc3_W  = tf.Variable(tf.truncated_normal(shape=(16, 10), mean = mu, stddev = sigma))\n","fc3_b  = tf.Variable(tf.zeros(10))\n","logits = tf.matmul(fc2, fc3_W) + fc3_b\n","\n","\n","\n","\n","cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n","loss_operation = tf.reduce_mean(cross_entropy)\n","optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n","training_operation = optimizer.minimize(loss_operation)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From <ipython-input-8-e95860d44fae>:59: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"AOMWE_Pcq1qv"},"source":["correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n","accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","saver = tf.train.Saver()\n","\n","def evaluate(X_data, y_data):\n","    num_examples = len(X_data)\n","    total_accuracy = 0\n","    sess = tf.get_default_session()\n","    for offset in range(0, num_examples, BATCH_SIZE):\n","        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n","        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n","        total_accuracy += (accuracy * len(batch_x))\n","    return total_accuracy / num_examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xS4yF4TFq1qw","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"error","timestamp":1632448391394,"user_tz":-540,"elapsed":284,"user":{"displayName":"송강산","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17478840785712769399"}},"outputId":"3c120833-d2ec-48f1-d231-0b41447f00b5"},"source":["with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    num_examples = len(X_train)\n","    \n","    print(\"Training...\")\n","    print()\n","    for i in range(EPOCHS):\n","        X_train, y_train = shuffle(X_train, y_train)\n","        for offset in range(0, num_examples, BATCH_SIZE):\n","            end = offset + BATCH_SIZE\n","            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n","            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n","            \n","        validation_accuracy = evaluate(X_validation, y_validation)\n","        print(\"EPOCH {} ...\".format(i+1))\n","        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n","        print()\n","        \n","    saver.save(sess, './lenet')\n","    print(\"Model saved\")\n","    \n","    # print weight and  bias\n","    \n","    "],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b6af0ef35f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"cell_type":"code","metadata":{"id":"IkqiWA7Eq1qx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677226683,"user_tz":-540,"elapsed":14,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"0dcbe735-2ece-4502-81df-7e9ad3fce8b5"},"source":["with tf.Session() as sess:\n","    saver.restore(sess, tf.train.latest_checkpoint('.'))\n","\n","    test_accuracy = evaluate(X_test, y_test)\n","    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from ./lenet\n","Test Accuracy = 0.988\n"]}]},{"cell_type":"code","metadata":{"scrolled":false,"id":"06dGgLVfq1qy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677227693,"user_tz":-540,"elapsed":1020,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"840c56fc-cfef-4bba-d4c5-746f174382e5"},"source":["#원본\n","np.set_printoptions(threshold = 1e6)\n","\n","with tf.Session() as sess:\n","    saver.restore(sess, tf.train.latest_checkpoint('.'))\n","    #print(\"logits\", sess.run(logits, feed_dict={x: X_test[0:1]}))\n","   \n","\n","    flog = open(\"weight1_0.log\", 'w')\n","    \n","    weight1 = sess.run(conv1_W)\n","    print(\"weight1: \", weight1.shape) \n","    #print(\"weight1: \", weight1) \n","    \n","    for i in range(5):\n","        for j in range(5):\n","            for o in range(6):\n","                if (weight1[i][j][0][o]*32768).astype(int) < 0 :\n","                    print(\"-\", file = flog, end='')\n","                #print(\"16'd%d, \"%(weight1[i][j][0][o]*256).astype(int) , file = flog, end=' ')\n","                print(\"%.4f, \"%abs(weight1[i][j][0][o]) , file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","        \n","    print(\"==========================conv1_bias==========================\", file = flog)        \n","    bias1 = sess.run(conv1_b)\n","    print(\"\", file = flog)   \n","    for o in range(6):\n","        if (bias1[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias1[o]), file = flog, end=' ')\n","        \n","    flog.close()\n","    \n","\n","####################################################    \n","\n","    flog = open(\"weight2_0.log\", 'w')\n","    \n","    weight2 = sess.run(conv2_W)\n","    print(\"weight2: \", weight2.shape)   \n","    \n","    for row in range(5):\n","        for col in range(5):\n","            for o in range(16):\n","                for i in range(6):\n","                    if (weight2[row][col][i][o]*32768).astype(int) < 0 :\n","                        print(\"-\", file = flog, end='')\n","                    print(\"%.4f, \"%abs(weight2[row][col][i][o]) , file = flog, end=' ')\n","                print(\"\", file = flog)\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","    \n","    print(\"\", file = flog)  \n","    \n","    bias2 = sess.run(conv2_b)\n","    print(\"bias2: \", bias2.shape)\n","    print(\"\", file = flog)\n","    print(\"\", file = flog)   \n","    print(\"==========================conv2_bias==========================\", file = flog) \n","    for o in range(16):\n","        if (bias2[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias2[o]), file = flog, end=' ')\n","        \n","        \n","    flog.close()\n","\n","####################################################   \n","    flog = open(\"fc1_0.log\", 'w')\n","    weight_fc1  = sess.run(fc1_W)\n","    \n","    print(\"weight_fc1: \", weight_fc1.shape)\n","    \n","    for o in range(32):\n","        for i in range(256):\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            if (weight_fc1[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            print(\"%.4f, \"%abs(weight_fc1[i][o]) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc1  = sess.run(fc1_b)\n","    print(\"bias_fc1: \", bias_fc1.shape)\n","    print(\"==========================bias_fc1==========================\", file = flog)   \n","    for o in range(32):\n","        if (bias_fc1[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias_fc1[o]) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc1_re = sess.run(fc1, feed_dict={x: X_test[0:1]})\n","    print(\"fc1_re: \", fc1_re.shape)\n","    print(\"==========================fc1_re==========================\", file = flog)   \n","    \n","    for i in range(32):\n","        print(\"%.4f, \"%fc1_re[0][i], file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","#################################################### \n","    flog = open(\"fc2_0.log\", 'w')\n","    weight_fc2  = sess.run(fc2_W)\n","    \n","    print(\"weight_fc2: \", weight_fc2.shape)\n","    \n","    for o in range(16):\n","        for i in range(32):\n","            if (weight_fc2[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            print(\"%.4f, \"%abs(weight_fc2[i][o]) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc2  = sess.run(fc2_b)\n","    print(\"bias_fc2: \", bias_fc2.shape)\n","    print(\"==========================bias_fc2==========================\", file = flog)  \n","    for o in range(16):\n","        if (bias_fc2[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias_fc2[o]) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc2_re = sess.run(fc2, feed_dict={x: X_test[0:1]})\n","    print(\"fc2_re: \", fc2_re.shape)\n","    print(\"==========================fc2_re==========================\", file = flog)   \n","    \n","    for i in range(16):\n","        print(\"%.4f, \"%fc2_re[0][i], file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","#################################################### \n","    flog = open(\"fc3_0.log\", 'w')\n","    weight_fc3  = sess.run(fc3_W)\n","    \n","    print(\"weight_fc3: \", weight_fc3.shape)\n","    \n","    for o in range(10):\n","        for i in range(16):\n","            if (weight_fc3[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            print(\"%.4f, \"%abs(weight_fc3[i][o]) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc3  = sess.run(fc3_b)\n","    print(\"bias_fc3: \", bias_fc3.shape)\n","    print(\"==========================bias_fc3==========================\", file = flog) \n","    for o in range(10):\n","        if (bias_fc3[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias_fc3[o]) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc3_re = sess.run(logits, feed_dict={x: X_test[0:1]})\n","    print(\"fc3_re: \", fc3_re.shape)\n","    print(\"==========================fc3_re==========================\", file = flog)   \n","    \n","    for i in range(10):\n","        print(\"%.4f, \"%fc3_re[0][i], file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from ./lenet\n","weight1:  (5, 5, 1, 6)\n","weight2:  (5, 5, 6, 16)\n","bias2:  (16,)\n","weight_fc1:  (256, 32)\n","bias_fc1:  (32,)\n","fc1_re:  (1, 32)\n","weight_fc2:  (32, 16)\n","bias_fc2:  (16,)\n","fc2_re:  (1, 16)\n","weight_fc3:  (16, 10)\n","bias_fc3:  (10,)\n","fc3_re:  (1, 10)\n"]}]},{"cell_type":"code","metadata":{"id":"LVnrA9Ab6XSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677228427,"user_tz":-540,"elapsed":735,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"d9c9ed50-daa2-4264-956d-c912b711c04a"},"source":["_#12bit\n","np.set_printoptions(threshold = 1e6)\n","\n","with tf.Session() as sess:\n","    saver.restore(sess, tf.train.latest_checkpoint('.'))\n","    #print(\"logits\", sess.run(logits, feed_dict={x: X_test[0:1]}))\n","   \n","\n","    flog = open(\"weight1_12.log\", 'w')\n","    \n","    weight1 = sess.run(conv1_W)\n","    print(\"weight1: \", weight1.shape) \n","    #print(\"weight1: \", weight1) \n","    \n","    for i in range(5):\n","        for j in range(5):\n","            for o in range(6):\n","                if (weight1[i][j][0][o]*2048).astype(int) < 0 :\n","                    print(\"-\", file = flog, end='')\n","                #print(\"16'd%d, \"%(weight1[i][j][0][o]*256).astype(int) , file = flog, end=' ')\n","                print(\"12'd%d, \"%abs((weight1[i][j][0][o]*2048).astype(int)) , file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","        \n","    print(\"==========================conv1_bias==========================\", file = flog)        \n","    bias1 = sess.run(conv1_b)\n","    print(\"\", file = flog)   \n","    for o in range(6):\n","        if (bias1[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias1[o]), file = flog, end=' ')\n","        \n","    flog.close()\n","    \n","\n","####################################################    \n","\n","    flog = open(\"weight2_12.log\", 'w')\n","    \n","    weight2 = sess.run(conv2_W)\n","    print(\"weight2: \", weight2.shape)   \n","    \n","    for row in range(5):\n","        for col in range(5):\n","            for o in range(16):\n","                for i in range(6):\n","                    if (weight2[row][col][i][o]*2048).astype(int) < 0 :\n","                        print(\"-\", file = flog, end='')\n","                    print(\"12'd%d, \"%abs((weight2[row][col][i][o]*2048).astype(int)) , file = flog, end=' ')\n","                print(\"\", file = flog)\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","    \n","    print(\"\", file = flog)  \n","    \n","    bias2 = sess.run(conv2_b)\n","    print(\"bias2: \", bias2.shape)\n","    print(\"\", file = flog)\n","    print(\"\", file = flog)   \n","    print(\"==========================conv2_bias==========================\", file = flog) \n","    for o in range(16):\n","        if (bias2[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"%.4f, \"%abs(bias2[o]), file = flog, end=' ')\n","        \n","        \n","    flog.close()\n","\n","####################################################   \n","    flog = open(\"fc1_12.log\", 'w')\n","    weight_fc1  = sess.run(fc1_W)\n","    \n","    print(\"weight_fc1: \", weight_fc1.shape)\n","    \n","    for o in range(32):\n","        for i in range(256):\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            if (weight_fc1[i][o]*2048).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            print(\"12'd%d, \"%abs((weight_fc1[i][o]*2048).astype(int)) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc1  = sess.run(fc1_b)\n","    print(\"bias_fc1: \", bias_fc1.shape)\n","    print(\"==========================bias_fc1==========================\", file = flog)   \n","    for o in range(32):\n","        if (bias_fc1[o]*2048*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"12'd%d, \"%abs((bias_fc1[o]*2048).astype(int)) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc1_re = sess.run(fc1, feed_dict={x: X_test[0:1]})\n","    print(\"fc1_re: \", fc1_re.shape)\n","    print(\"==========================fc1_re==========================\", file = flog)   \n","    \n","    for i in range(32):\n","        print(\"12'd%d, \"%(fc1_re[0][i]*2048).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","#################################################### \n","    flog = open(\"fc2_12.log\", 'w')\n","    weight_fc2  = sess.run(fc2_W)\n","    \n","    print(\"weight_fc2: \", weight_fc2.shape)\n","    \n","    for o in range(16):\n","        for i in range(32):\n","            if (weight_fc2[i][o]*2048).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            print(\"12'd%d, \"%abs(weight_fc2[i][o]) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc2  = sess.run(fc2_b)\n","    print(\"bias_fc2: \", bias_fc2.shape)\n","    print(\"==========================bias_fc2==========================\", file = flog)  \n","    for o in range(16):\n","        if (bias_fc2[o]*2048*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"12'd%d, \"%abs(bias_fc2[o]) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc2_re = sess.run(fc2, feed_dict={x: X_test[0:1]})\n","    print(\"fc2_re: \", fc2_re.shape)\n","    print(\"==========================fc2_re==========================\", file = flog)   \n","    \n","    for i in range(16):\n","        print(\"12'd%d, \"%(fc2_re[0][i]*2048).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","#################################################### \n","    flog = open(\"fc3_12.log\", 'w')\n","    weight_fc3  = sess.run(fc3_W)\n","    \n","    print(\"weight_fc3: \", weight_fc3.shape)\n","    \n","    for o in range(10):\n","        for i in range(16):\n","            if (weight_fc3[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            print(\"%.4f, \"%abs(weight_fc3[i][o]) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc3  = sess.run(fc3_b)\n","    print(\"bias_fc3: \", bias_fc3.shape)\n","    print(\"==========================bias_fc3==========================\", file = flog) \n","    for o in range(10):\n","        if (bias_fc3[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"12'd%d, \"%abs((bias_fc3[o]*2048).astype(int)) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc3_re = sess.run(logits, feed_dict={x: X_test[0:1]})\n","    print(\"fc3_re: \", fc3_re.shape)\n","    print(\"==========================fc3_re==========================\", file = flog)   \n","    \n","    for i in range(10):\n","        print(\"12'd%d, \"%(fc3_re[0][i]*2048).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from ./lenet\n","weight1:  (5, 5, 1, 6)\n","weight2:  (5, 5, 6, 16)\n","bias2:  (16,)\n","weight_fc1:  (256, 32)\n","bias_fc1:  (32,)\n","fc1_re:  (1, 32)\n","weight_fc2:  (32, 16)\n","bias_fc2:  (16,)\n","fc2_re:  (1, 16)\n","weight_fc3:  (16, 10)\n","bias_fc3:  (10,)\n","fc3_re:  (1, 10)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBXfbmlPQNL3","executionInfo":{"status":"ok","timestamp":1630677229184,"user_tz":-540,"elapsed":759,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"7a3d36b1-a6dc-438d-b7cc-01e84cb4036b"},"source":["#16bit\n","np.set_printoptions(threshold = 1e6)\n","\n","with tf.Session() as sess:\n","    saver.restore(sess, tf.train.latest_checkpoint('.'))\n","    #print(\"logits\", sess.run(logits, feed_dict={x: X_test[0:1]}))\n","   \n","\n","    flog = open(\"weight1_16.log\", 'w')\n","    \n","    weight1 = sess.run(conv1_W)\n","    print(\"weight1: \", weight1.shape) \n","    #print(\"weight1: \", weight1) \n","    \n","    for i in range(5):\n","        for j in range(5):\n","            for o in range(6):\n","                if (weight1[i][j][0][o]*32768).astype(int) < 0 :\n","                    print(\"-\", file = flog, end='')\n","                #print(\"16'd%d, \"%(weight1[i][j][0][o]*256).astype(int) , file = flog, end=' ')\n","                print(\"16'd%d, \"%abs((weight1[i][j][0][o]*32768).astype(int)) , file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","        \n","    print(\"==========================conv1_bias==========================\", file = flog)        \n","    bias1 = sess.run(conv1_b)\n","    print(\"\", file = flog)   \n","    for o in range(6):\n","        if (bias1[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"24'd%d, \"%abs((bias1[o]*32768*256).astype(int)), file = flog, end=' ')\n","        \n","    flog.close()\n","    \n","\n","####################################################    \n","\n","    flog = open(\"weight2_16.log\", 'w')\n","    \n","    weight2 = sess.run(conv2_W)\n","    print(\"weight2: \", weight2.shape)   \n","    \n","    for row in range(5):\n","        for col in range(5):\n","            for o in range(16):\n","                for i in range(6):\n","                    if (weight2[row][col][i][o]*32768).astype(int) < 0 :\n","                        print(\"-\", file = flog, end='')\n","                    print(\"16'd%d, \"%abs((weight2[row][col][i][o]*32768).astype(int)) , file = flog, end=' ')\n","                print(\"\", file = flog)\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","    \n","    print(\"\", file = flog)  \n","    \n","    bias2 = sess.run(conv2_b)\n","    print(\"bias2: \", bias2.shape)\n","    print(\"\", file = flog)\n","    print(\"\", file = flog)   \n","    print(\"==========================conv2_bias==========================\", file = flog) \n","    for o in range(16):\n","        if (bias2[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"24'd%d, \"%abs((bias2[o]*32768*256).astype(int)), file = flog, end=' ')\n","        \n","        \n","    flog.close()\n","\n","####################################################   \n","    flog = open(\"fc1_16.log\", 'w')\n","    weight_fc1  = sess.run(fc1_W)\n","    \n","    print(\"weight_fc1: \", weight_fc1.shape)\n","    \n","    for o in range(32):\n","        for i in range(256):\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            if (weight_fc1[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            print(\"16'd%d, \"%abs((weight_fc1[i][o]*32768).astype(int)) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc1  = sess.run(fc1_b)\n","    print(\"bias_fc1: \", bias_fc1.shape)\n","    print(\"==========================bias_fc1==========================\", file = flog)   \n","    for o in range(32):\n","        if (bias_fc1[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"24'd%d, \"%abs((bias_fc1[o]*32768*256).astype(int)) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc1_re = sess.run(fc1, feed_dict={x: X_test[0:1]})\n","    print(\"fc1_re: \", fc1_re.shape)\n","    print(\"==========================fc1_re==========================\", file = flog)   \n","    \n","    for i in range(32):\n","        print(\"%6d, \"%(fc1_re[0][i]*256).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","#################################################### \n","    flog = open(\"fc2_16.log\", 'w')\n","    weight_fc2  = sess.run(fc2_W)\n","    \n","    print(\"weight_fc2: \", weight_fc2.shape)\n","    \n","    for o in range(16):\n","        for i in range(32):\n","            if (weight_fc2[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            print(\"16'd%d, \"%abs((weight_fc2[i][o]*32768).astype(int)) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc2  = sess.run(fc2_b)\n","    print(\"bias_fc2: \", bias_fc2.shape)\n","    print(\"==========================bias_fc2==========================\", file = flog)  \n","    for o in range(16):\n","        if (bias_fc2[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"24'd%d, \"%abs((bias_fc2[o]*32768*256).astype(int)) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc2_re = sess.run(fc2, feed_dict={x: X_test[0:1]})\n","    print(\"fc2_re: \", fc2_re.shape)\n","    print(\"==========================fc2_re==========================\", file = flog)   \n","    \n","    for i in range(16):\n","        print(\"%6d, \"%(fc2_re[0][i]*256).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","#################################################### \n","    flog = open(\"fc3_16.log\", 'w')\n","    weight_fc3  = sess.run(fc3_W)\n","    \n","    print(\"weight_fc3: \", weight_fc3.shape)\n","    \n","    for o in range(10):\n","        for i in range(16):\n","            if (weight_fc3[i][o]*32768).astype(int) < 0 :\n","                print(\"-\", file = flog, end='')\n","            #print( \"%2f, \"%weight_fc1[i][o], file = flog, end=' ')\n","            #print(\"%6d, \"%(weight_fc1[i][o]).astype(int) , file = flog, end=' ')\n","            print(\"16'd%d, \"%abs((weight_fc3[i][o]*32768).astype(int)) , file = flog, end=' ')\n","            if i%16==15 :\n","                print(\"\", file = flog) \n","        print(\"\", file = flog)  \n","    bias_fc3  = sess.run(fc3_b)\n","    print(\"bias_fc3: \", bias_fc3.shape)\n","    print(\"==========================bias_fc3==========================\", file = flog) \n","    for o in range(10):\n","        if (bias_fc3[o]*32768*256).astype(int) < 0 :\n","            print(\"-\", file = flog, end='')\n","        print(\"24'd%d, \"%abs((bias_fc3[o]*32768*256).astype(int)) , file = flog, end=' ')\n","        if o%16==15 :\n","            print(\"\", file = flog)  \n","    print(\"\", file = flog)   \n","    \n","    fc3_re = sess.run(logits, feed_dict={x: X_test[0:1]})\n","    print(\"fc3_re: \", fc3_re.shape)\n","    print(\"==========================fc3_re==========================\", file = flog)   \n","    \n","    for i in range(10):\n","        print(\"%6d, \"%(fc3_re[0][i]*256).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    print(\"\", file = flog)  \n","    \n","    flog.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from ./lenet\n","weight1:  (5, 5, 1, 6)\n","weight2:  (5, 5, 6, 16)\n","bias2:  (16,)\n","weight_fc1:  (256, 32)\n","bias_fc1:  (32,)\n","fc1_re:  (1, 32)\n","weight_fc2:  (32, 16)\n","bias_fc2:  (16,)\n","fc2_re:  (1, 16)\n","weight_fc3:  (16, 10)\n","bias_fc3:  (10,)\n","fc3_re:  (1, 10)\n"]}]},{"cell_type":"code","metadata":{"id":"82KZzF_Vq1q1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677230451,"user_tz":-540,"elapsed":1269,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"94ecfaea-5552-47ca-fea7-743f4cdab73c"},"source":["# test \n","np.set_printoptions(threshold = 1e6)\n","\n","with tf.Session() as sess:\n","    saver.restore(sess, tf.train.latest_checkpoint('.'))\n","    \n","        \n","####################################################     \n","    flog = open(\"conv1.log\", 'w')\n","    \n","    conv1_test   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n","    relu1 = tf.nn.relu(conv1_test)\n","    \n","    conv_re = sess.run(conv1_test, feed_dict={x: X_test[0:1]})\n","    relu1_re = sess.run(relu1, feed_dict={x: X_test[0:1]})\n","    conv1\n","    pool1_re = sess.run(conv1, feed_dict={x: X_test[0:1]})\n","    print(\"conv1: \", conv_re.shape) \n","    #print(\"conv1: \", conv_re) \n","    print(\"relu1: \", relu1.shape) \n","    print(\"pool1_re: \", pool1_re.shape) \n","    \n","    \n","    print(\"conv1: \", conv_re.shape, file = flog) \n","    #print(\"conv1: \", conv_re, file = flog) \n","    for o in range(6):\n","        for i in range(24):\n","            for j in range(24):\n","                print(conv_re[0][i][j][o], file = flog, end=' ')\n","                #print(relu1_re[0][i][j][o], file = flog, end='     ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","    \n","\n","    print(\"\", file = flog)      \n","    for i in range(24):\n","        for j in range(24):\n","            for o in range(6):\n","                print(\"%6d, \"%(conv_re[0][i][j][o]*256).astype(int), file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)    \n","        \n","    print(\"==========================pool1_re==========================\", file = flog)     \n","    \n","    print(\"\", file = flog)      \n","    for i in range(12):\n","        for j in range(12):\n","            for o in range(6):\n","                print(\"%6d, \"%(pool1_re[0][i][j][o]*256).astype(int), file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)    \n","    flog.close()\n","    \n","####################################################        \n","    \n","    conv2_in = tf.placeholder(tf.float32, (None, 12, 12, 6))\n","    \n","    ones28x28x6 = np.ones(12*12*6)\n","    ones28x28x6 = ones28x28x6.reshape(1, 12, 12, 6)\n","    #tensor32x32x6\n","    \n","    flog = open(\"conv2.log\", 'w')\n","    \n","    conv2_test   = tf.nn.conv2d(conv2_in, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n","    #conv2_test   = tf.nn.conv2d(conv2_in, conv2_W, strides=[1, 1, 1, 1], padding='VALID')\n","    conv2_2d   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n","    \n","    \n","    #conv2_test   = tf.nn.conv2d(conv2_in, conv2_W, strides=[1, 1, 1, 1], padding='VALID')\n","    conv2_re = sess.run(conv2_2d, feed_dict={x: X_test[0:1]})\n","    #conv2_re = sess.run(conv2_test, feed_dict={conv2_in: ones32x32x6})\n","    print(\"conv2: \", conv2_re.shape)    \n","    \n","    print(\"\", file = flog)      \n","    for i in range(8):\n","        for j in range(8):\n","            for o in range(16):\n","                print(\"%d, \"%(conv2_re[0][i][j][o]*256).astype(int), file = flog, end=' ')\n","                #print(\"%6d, \"%(conv2_re[0][i][j][o]).astype(int), file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)    \n","        \n","    pool2_re = sess.run(conv2, feed_dict={x: X_test[0:1]})\n","    print(\"==========================pool2_re==========================\", file = flog)     \n","    print(\"pool2_re: \", pool2_re.shape)  \n","    print(\"\", file = flog)      \n","    for i in range(4):\n","        for j in range(4):\n","            for o in range(16):\n","                print(\"%6d, \"%(pool2_re[0][i][j][o]*256).astype(int), file = flog, end=' ')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)   \n","        \n","        \n","    fc0_re = sess.run(fc0, feed_dict={x: X_test[0:1]})\n","    print(\"fc0_re: \", fc0_re.shape)  \n","    print(\"==========================fc0_re==========================\", file = flog)     \n","    \n","    for i in range(256):\n","        print(\"%6d, \"%(fc0_re[0][i]*256).astype(int), file = flog, end=' ')\n","        if i%16==15 :\n","            print(\"\", file = flog) \n","    flog.close()      \n","        \n","        \n","        \n","####################################################        \n","    \n","    flog = open(\"test_digits.log\", 'w')\n","    print(\"X_test: \", X_test.shape)\n","    for n in range(100):\n","        for i in range(28):\n","            for j in range(28):\n","                print(\"%4d, \"%(X_test[n][i][j][0]*255).astype(int), file = flog, end='')\n","            print(\"\", file = flog)\n","        print(\"\", file = flog)\n","        print(\"\", file = flog)\n","        \n","    fc3_re = sess.run(logits, feed_dict={x: X_test[0:100]})\n","    print(\"fc3_re: \", fc3_re.shape)\n","    print(\"==========================fc3_re==========================\", file = flog)   \n","    \n","    for n in range(100):\n","        for i in range(10):\n","            print(\"%6d, \"%(fc3_re[n][i]*256).astype(int), file = flog, end=' ')\n","        print(\"\", file = flog)\n","        \n","        \n","    print(\"===========================digits=========================\", file = flog)   \n","    y_test\n","    print(\"y_test: \", y_test.shape)\n","    for n in range(100):\n","        print(\"%d, %d\"% (n, y_test[n]), file = flog, end=' ')\n","        print(\"\", file = flog)  \n","        \n","    print(\"\", file = flog)  \n","    \n","    flog.close()\n","    \n","    "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Restoring parameters from ./lenet\n","conv1:  (1, 24, 24, 6)\n","relu1:  (?, 24, 24, 6)\n","pool1_re:  (1, 12, 12, 6)\n","conv2:  (1, 8, 8, 16)\n","pool2_re:  (1, 4, 4, 16)\n","fc0_re:  (1, 256)\n","X_test:  (10000, 28, 28, 1)\n","fc3_re:  (100, 10)\n","y_test:  (10000,)\n"]}]},{"cell_type":"code","metadata":{"id":"RcBRLXKLVhr-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630677230451,"user_tz":-540,"elapsed":7,"user":{"displayName":"송강산","photoUrl":"","userId":"17478840785712769399"}},"outputId":"e450df58-f5d9-46a9-e9b6-aa602b6e0149"},"source":["total_parameters = 0\n","for variable in tf.trainable_variables():\n","    # shape is an array of tf.Dimension\n","    shape = variable.get_shape()\n","    print(\"shape\", shape)\n","    print(len(shape))\n","    variable_parameters = 1\n","    for dim in shape:\n","        print(\"dim\", dim)\n","        variable_parameters *= dim.value\n","    print(\"variable_parameters\", variable_parameters)\n","    total_parameters += variable_parameters\n","print(\"total_parameters\", total_parameters)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["shape (5, 5, 1, 6)\n","4\n","dim 5\n","dim 5\n","dim 1\n","dim 6\n","variable_parameters 150\n","shape (6,)\n","1\n","dim 6\n","variable_parameters 6\n","shape (5, 5, 6, 16)\n","4\n","dim 5\n","dim 5\n","dim 6\n","dim 16\n","variable_parameters 2400\n","shape (16,)\n","1\n","dim 16\n","variable_parameters 16\n","shape (256, 32)\n","2\n","dim 256\n","dim 32\n","variable_parameters 8192\n","shape (32,)\n","1\n","dim 32\n","variable_parameters 32\n","shape (32, 16)\n","2\n","dim 32\n","dim 16\n","variable_parameters 512\n","shape (16,)\n","1\n","dim 16\n","variable_parameters 16\n","shape (16, 10)\n","2\n","dim 16\n","dim 10\n","variable_parameters 160\n","shape (10,)\n","1\n","dim 10\n","variable_parameters 10\n","total_parameters 11494\n"]}]}]}